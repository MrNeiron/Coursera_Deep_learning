{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CreateMaskForWindow(x):\n",
    "    \"\"\"\n",
    "    Creates a mask from an input matrix x, to identify the max entry of x.\n",
    "    \n",
    "    Arguments:\n",
    "    x -- Array of shape (f, f)\n",
    "    \n",
    "    Returns:\n",
    "    mask -- Array of the same shape as window, contains a True at the position corresponding to the max entry of x.\n",
    "    \"\"\"\n",
    "    \n",
    "    ### START CODE HERE ### (≈1 line)\n",
    "    mask = x == np.max(x)\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x(2, 3): \n",
      "[[ 1.62434536 -0.61175641 -0.52817175]\n",
      " [-1.07296862  0.86540763 -2.3015387 ]]\n",
      "mask(2, 3): \n",
      "[[ True False False]\n",
      " [False False False]]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "x = np.random.randn(2,3)\n",
    "mask = CreateMaskForWindow(x)\n",
    "print(\"x{}: \\n{}\".format(x.shape,x))\n",
    "print(\"mask{}: \\n{}\".format(mask.shape, mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DistributeValue(dz, shape):\n",
    "    \"\"\"\n",
    "    Distributes the input value in the matrix of dimension shape\n",
    "    \n",
    "    Arguments:\n",
    "    dz -- input scalar\n",
    "    shape -- the shape (n_H, n_W) of the output matrix for which we want to distribute the value of dz\n",
    "    \n",
    "    Returns:\n",
    "    a -- Array of size (n_H, n_W) for which we distributed the value of dz\n",
    "    \"\"\"\n",
    "    ### START CODE HERE ###\n",
    "    # Retrieve dimensions from shape (≈1 line)\n",
    "    (n_H, n_W) = shape\n",
    "    \n",
    "    # Compute the value to distribute on the matrix (≈1 line)\n",
    "    average = dz / (n_H * n_W)\n",
    "    \n",
    "    # Create a matrix where every entry is the \"average\" value (≈1 line)\n",
    "    a = np.ones(shape) * average\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a(2, 2): \n",
      "[[0.5 0.5]\n",
      " [0.5 0.5]]\n"
     ]
    }
   ],
   "source": [
    "dz = 2\n",
    "prevShape = (2,2)\n",
    "a = DistributeValue(dz,prevShape)\n",
    "print(\"a{}: \\n{}\".format(a.shape,a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: pool_forward\n",
    "\n",
    "def PoolForward(Aprev, hyperparameters, mode = \"max\"):\n",
    "    \"\"\"\n",
    "    Implements the forward pass of the pooling layer\n",
    "    \n",
    "    Arguments:\n",
    "    A_prev -- Input data, numpy array of shape (m, nH, nW, nC)\n",
    "    hparameters -- python dictionary containing \"f\" and \"stride\"\n",
    "    mode -- the pooling mode you would like to use, defined as a string (\"max\" or \"average\")\n",
    "    \n",
    "    Returns:\n",
    "    A -- output of the pool layer, a numpy array of shape (m, nH, nW, nC)\n",
    "    cache -- cache used in the backward pass of the pooling layer, contains the input and hparameters \n",
    "    \"\"\"\n",
    "    \n",
    "    # Retrieve hyperparameters from \"hparameters\"\n",
    "    stride = hyperparameters[\"stride\"]\n",
    "    f= hyperparameters['f']\n",
    "    \n",
    "    # Retrieve dimensions from the input shape\n",
    "    (m, nH, nW, nC) = Aprev.shape#Input shape of the tensor\n",
    "    \n",
    "    # Define the dimensions of the output\n",
    "    newNH = int((nH - f)/stride)+1#Output height of the tensor\n",
    "    newNW = int((nH - f)/stride)+1#Output width of the tensor\n",
    "    \n",
    "    # Initialize output matrix A\n",
    "    A = np.zeros((m,newNH, newNW, nC), dtype=np.int32)#Output tensor\n",
    "    \n",
    "    \n",
    "    ### START CODE HERE ###\n",
    "    for m1 in range(m):                                             # loop over the training examples\n",
    "        for i,h1 in enumerate(range(0,nH,stride)):                  # loop on the vertical axis of the output volume\n",
    "            for j,w1 in enumerate(range(0,nW,stride)):              # loop on the horizontal axis of the output volume\n",
    "                for c1 in range(nC):                                # loop over the channels of the output volume\n",
    "                    try:\n",
    "                        if mode == \"max\":\n",
    "                            A[m1,i,j,c1] = np.max(Aprev[m1,h1:h1+f,w1:w1+f,c1]) \n",
    "                        elif mode == \"average\":\n",
    "                            A[m1,i,j,c1] = int(np.mean(Aprev[m1,h1:h1+f,w1:w1+f,c1]))\n",
    "                    except:\n",
    "                        break\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Store the input and hparameters in \"cache\" for BackPropagationPool()\n",
    "    cache = (Aprev, hyperparameters, mode)# Parameters for back propagation\n",
    "    \n",
    "    return A, cache\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BackPropagationPool(dA, cache, mode = None):\n",
    "    \"\"\"\n",
    "    Implements the backward pass of the pooling layer\n",
    "    \n",
    "    Arguments:\n",
    "    dA -- gradient of cost with respect to the output of the pooling layer, same shape as A\n",
    "    cache -- cache output from the forward pass of the pooling layer, contains the layer's input and hparameters \n",
    "    mode -- the pooling mode you would like to use, defined as a string (\"max\" or \"average\")\n",
    "    \n",
    "    Returns:\n",
    "    dA_prev -- gradient of cost with respect to the input of the pooling layer, same shape as A_prev\n",
    "    \"\"\"\n",
    "    ### START CODE HERE ###\n",
    "    \n",
    "    # Retrieve information from cache (≈1 line)\n",
    "    (Aprev, hyperparameters, modeCache) = cache\n",
    "    \n",
    "    print(\"m: \",mode)\n",
    "    mode = \"max\" if mode == None and modeCache == None else modeCache if mode == None else mode \n",
    "    \n",
    "    # Retrieve hyperparameters from \"hparameters\" (≈2 lines)\n",
    "    stride = hyperparameters[\"stride\"]\n",
    "    f = hyperparameters[\"f\"]\n",
    "    \n",
    "    # Retrieve dimensions from A_prev's shape and dA's shape (≈2 lines)\n",
    "    (m, nHprev, nWprev, nCprev) = Aprev.shape\n",
    "    (m, nH, nW, nC) = dA.shape\n",
    "    \n",
    "    # Initialize dA_prev with zeros (≈1 line)\n",
    "    dAprev = np.zeros(Aprev.shape)\n",
    "    \n",
    "    for m1 in range(m):                                               # loop over the training examples\n",
    "        for i,h1 in enumerate(range(0,nHprev-f+1, stride)):           # loop on the vertical axis\n",
    "            print(\"h1: \",h1)\n",
    "            for j,w1 in enumerate(range(0,nWprev-f+1, stride)):       # loop on the horizontal axis\n",
    "                print(\"w1: \",w1)\n",
    "                for c1 in range(nC):                                  # loop over the channels (depth)\n",
    "                    # Compute the backward propagation in both modes.\n",
    "                    #print(\"1)dAprev{}: \\n{}\".format(dAprev[m1,h1:h1+f,w1:w1+f,c1].shape,dAprev[m1,h1:h1+f,w1:w1+f,c1]))\n",
    "\n",
    "                    if mode == \"max\": \n",
    "                        dAprev[m1,h1:h1+f,w1:w1+f,c1] += CreateMaskForWindow(Aprev[m1,h1:h1+f,w1:w1+f,c1]) * dA[m1,i,j,c1]\n",
    "                    elif mode == \"average\":\n",
    "                        #print(\"dA{}: \\n{}\".format(dA[m1,i,j,c1].shape,dA[m1,i,j,c1]))\n",
    "                        s = DistributeValue(dA[m1,i,j,c1], (f,f))\n",
    "                        dAprev[m1,h1:h1+f,w1:w1+f,c1] += s\n",
    "                    #print(\"2)dAprev{}: \\n{}\".format(dAprev[m1,h1:h1+f,w1:w1+f,c1].shape,dAprev[m1,h1:h1+f,w1:w1+f,c1]))\n",
    "\n",
    "                  \n",
    "    ### END CODE ###\n",
    "    \n",
    "    # Making sure your output shape is correct\n",
    "    assert(dAprev.shape == Aprev.shape)\n",
    "    \n",
    "    return dAprev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m:  max\n",
      "h1:  0\n",
      "w1:  0\n",
      "w1:  2\n",
      "h1:  2\n",
      "w1:  0\n",
      "w1:  2\n",
      "h1:  4\n",
      "w1:  0\n",
      "w1:  2\n",
      "h1:  0\n",
      "w1:  0\n",
      "w1:  2\n",
      "h1:  2\n",
      "w1:  0\n",
      "w1:  2\n",
      "h1:  4\n",
      "w1:  0\n",
      "w1:  2\n",
      "h1:  0\n",
      "w1:  0\n",
      "w1:  2\n",
      "h1:  2\n",
      "w1:  0\n",
      "w1:  2\n",
      "h1:  4\n",
      "w1:  0\n",
      "w1:  2\n",
      "h1:  0\n",
      "w1:  0\n",
      "w1:  2\n",
      "h1:  2\n",
      "w1:  0\n",
      "w1:  2\n",
      "h1:  4\n",
      "w1:  0\n",
      "w1:  2\n",
      "h1:  0\n",
      "w1:  0\n",
      "w1:  2\n",
      "h1:  2\n",
      "w1:  0\n",
      "w1:  2\n",
      "h1:  4\n",
      "w1:  0\n",
      "w1:  2\n",
      "\n",
      "mode:  max\n",
      "dAprev(5, 3): \n",
      "[[-0.31011677  0.          1.0388246 ]\n",
      " [ 0.          0.          0.        ]\n",
      " [ 0.44136444  0.         -0.13644474]\n",
      " [ 0.          0.          0.        ]\n",
      " [ 0.01740941  0.         -0.51709446]]\n",
      "m:  average\n",
      "h1:  0\n",
      "w1:  0\n",
      "w1:  2\n",
      "h1:  2\n",
      "w1:  0\n",
      "w1:  2\n",
      "h1:  4\n",
      "w1:  0\n",
      "w1:  2\n",
      "h1:  0\n",
      "w1:  0\n",
      "w1:  2\n",
      "h1:  2\n",
      "w1:  0\n",
      "w1:  2\n",
      "h1:  4\n",
      "w1:  0\n",
      "w1:  2\n",
      "h1:  0\n",
      "w1:  0\n",
      "w1:  2\n",
      "h1:  2\n",
      "w1:  0\n",
      "w1:  2\n",
      "h1:  4\n",
      "w1:  0\n",
      "w1:  2\n",
      "h1:  0\n",
      "w1:  0\n",
      "w1:  2\n",
      "h1:  2\n",
      "w1:  0\n",
      "w1:  2\n",
      "h1:  4\n",
      "w1:  0\n",
      "w1:  2\n",
      "h1:  0\n",
      "w1:  0\n",
      "w1:  2\n",
      "h1:  2\n",
      "w1:  0\n",
      "w1:  2\n",
      "h1:  4\n",
      "w1:  0\n",
      "w1:  2\n",
      "\n",
      "mode:  average\n",
      "dAprev(5, 3): \n",
      "[[-0.31011677  0.          1.0388246 ]\n",
      " [ 0.          0.          0.        ]\n",
      " [ 0.44136444  0.         -0.13644474]\n",
      " [ 0.          0.          0.        ]\n",
      " [ 0.01740941  0.         -0.51709446]]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "Aprev = np.random.randn(5,5,3,2)\n",
    "hyperparameters = {\"stride\": 2, \"f\":1}\n",
    "A, cache = PoolForward(Aprev, hyperparameters)\n",
    "dA = np.random.randn(5,4,2,2,)\n",
    "#print(\"dA{}: \\n{}\".format(dA.shape,dA))\n",
    "modes = (\"max\",\"average\")\n",
    "\n",
    "for mode in modes:\n",
    "    dAprev = BackPropagationPool(dA, cache, mode)\n",
    "    print(\"\\nmode: \", mode)\n",
    "    print(\"dAprev{}: \\n{}\".format(dAprev[0,:,:,0].shape,dAprev[0,:,:,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
